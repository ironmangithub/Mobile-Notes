NPU: neural processing unit, an AI Accelerator, a specialized circuit; implements all the necessary control and arithmetic logic necessary to execute machine learning algorithms.

Mobile GPU: mobile graphics processing unit, is a dedicated co-processor designed to accelerate graphics applications, user interfaces, and 3D content on your smartphone, tablet, wearables, and IoT devices.

XNNPACK: is a highly optimized library of floating-point neural network inference operators for ARM, WebAssembly, and x86 platforms.

NNAPI: The Android Neural Networks API (NNAPI) is an Android C API designed for running computationally intensive operations for machine learning on Android devices. 

Core ML: is an Apple framework to integrate machine learning models into your app.

TensorFlow Lite: is a mobile library for deploying models on mobile, microcontrollers and other edge devices.

PyTorch Mobile: End-to-end workflow from Training to Deployment for iOS and Android mobile devices. 

EP: Execution Providers - onnxruntime, ONNX Runtime works with different hardware acceleration libraries through its extensible Execution Providers (EP) framework to optimally execute the ONNX models on the hardware platform.
